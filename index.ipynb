{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Concerts - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen how to scrape a simple website, it's time to again practice those skills on a full-fledged site!\n",
    "In this lab, you'll practice your scraping skills on a music website: https://www.residentadvisor.net.\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Scrape events from a website\n",
    "* Follow links to those events to retrieve further information\n",
    "* Clean and store scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Website\n",
    "\n",
    "For this lab, you'll be scraping the https://www.residentadvisor.net website. Start by navigating to the events page [here](https://www.residentadvisor.net/events) in your browser.\n",
    "\n",
    "<img src=\"images/ra.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the https://www.residentadvisor.net/events page in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Inspect Element Feature\n",
    "\n",
    "Next, open the inspect element feature from your web browser in order to preview the underlying HTML associated with the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the inspect element feature in your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Scrape all of the Events on the Given Page Events Page\n",
    "\n",
    "The function should return a Pandas DataFrame with columns for the Event_Name, Venue, Event_Date and Number_of_Attendees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_events(events_page_url):\n",
    "    #Your code here\n",
    "    df.columns = [\"Event_Name\", \"Venue\", \"Event_Date\", \"Number_of_Attendees\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploration; designing/testing function parts\n",
    "response = requests.get(\"https://www.residentadvisor.net/events/us/newyork\")\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_listings = soup.find('div', id=\"event-listing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 <li><p class=\"eventDate date\"><a href=\"/events.aspx?ai=8&amp;v=day&amp;mn=5&amp;yr=2019&amp;dy=20\"><span>Mon, 20 May 2019 /</span></a></p></li>\n"
     ]
    }
   ],
   "source": [
    "entries = event_listings.findAll('li')\n",
    "print(len(entries), entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paradisco: Season Farewell</td>\n",
       "      <td>Le Bain</td>\n",
       "      <td>Mon, 20 May 2019 /</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Body Music Therapy with Jen Orlando</td>\n",
       "      <td>Nowadays</td>\n",
       "      <td>Mon, 20 May 2019 /</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Channel Tres</td>\n",
       "      <td>Elsewhere</td>\n",
       "      <td>Tue, 21 May 2019 /</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delivery. Polanco, Pereira, La Carta, Bytz, Pjay</td>\n",
       "      <td>Ms. Yoo</td>\n",
       "      <td>Tue, 21 May 2019 /</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Funky People - Funky FAM Throwdown // DKDS, 3C...</td>\n",
       "      <td>TBA Brooklyn</td>\n",
       "      <td>Tue, 21 May 2019 /</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0             1  \\\n",
       "0                         Paradisco: Season Farewell       Le Bain   \n",
       "1                Body Music Therapy with Jen Orlando      Nowadays   \n",
       "2                                       Channel Tres     Elsewhere   \n",
       "3   Delivery. Polanco, Pereira, La Carta, Bytz, Pjay       Ms. Yoo   \n",
       "4  Funky People - Funky FAM Throwdown // DKDS, 3C...  TBA Brooklyn   \n",
       "\n",
       "                    2     3  \n",
       "0  Mon, 20 May 2019 /   4.0  \n",
       "1  Mon, 20 May 2019 /   3.0  \n",
       "2  Tue, 21 May 2019 /  10.0  \n",
       "3  Tue, 21 May 2019 /   8.0  \n",
       "4  Tue, 21 May 2019 /   5.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Successive exploration in function development\n",
    "rows = []\n",
    "for entry in entries:\n",
    "    #Is it a date? If so, set current date.\n",
    "    date = entry.find('p', class_=\"eventDate date\")\n",
    "    event = entry.find('h1', class_=\"event-title\")\n",
    "    if event:\n",
    "        details = event.text.split(' at ')\n",
    "        event_name = details[0].strip()\n",
    "        venue = details[1].strip()\n",
    "        try:\n",
    "            n_attendees = int(re.match(\"(\\d*)\", entry.find('p', class_=\"attending\").text)[0])\n",
    "        except:\n",
    "            n_attendees = np.nan\n",
    "        rows.append([event_name, venue, cur_date, n_attendees])\n",
    "    elif date:\n",
    "        cur_date = date.text\n",
    "    else:\n",
    "        continue\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Function to Retrieve the URL for the Next Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/events/us/newyork/week/2019-05-27'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function development cell\n",
    "soup.find('a', attrs={'ga-event-action':\"Next \"}).attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    url_ext = soup.find('a', attrs={'ga-event-action':\"Next \"}).attrs['href']\n",
    "    next_page_url = \"https://www.residentadvisor.net\" + url_ext\n",
    "    #Your code here\n",
    "    return next_page_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Next 1000 Events for Your Area\n",
    "\n",
    "Display the data sorted by the number of attendees. If there is a tie for the number attending, sort by event date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Congratulations! In this lab, you successfully scraped a website for concert event information!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
